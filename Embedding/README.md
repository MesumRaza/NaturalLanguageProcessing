## Embedding

### Overview
* [Tutorial on EMNLP 14'](http://emnlp2014.org/tutorials/8_notes.pdf)
* [Distributional and Word Embedding Models](https://github.com/Lambda-3/Indra/wiki/Distributional-and-Word-Embedding-Models)

### Word2Vec
* Overview by Xin Rong *[word2vec Parameter Learning Explained](https://arxiv.org/pdf/1411.2738.pdf)* [[Video] (https://www.youtube.com/watch?v=D-ekE-Wlcds)]*
* Explanation of Negative Sampling *[word2vec Explained:  Deriving Mikolov et al.â€™s Negative-Sampling Word-Embedding Method](https://arxiv.org/pdf/1402.3722.pdf)*
* Connection of Negative Sampling and Mutual Information *[Neural Word Embedding as Implicit Matrix Factorization](https://pdfs.semanticscholar.org/e0d7/69c5698275c2f745c1aac2aebc323f51aa24.pdf?_ga=2.100986117.540785117.1516862569-662515382.1516862569)* 14'

#### Variant
* emoji2vec 
Ben Eisner *[emoji2vec
: Learning Emoji Representations from their Description](http://aclweb.org/anthology/W16-6208)* 15'

### Glove



